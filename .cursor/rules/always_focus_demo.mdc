---
description: 
globs: 
alwaysApply: true
---
# Failover Composition and Parcel Merge (FCP-PM) Mechanism

The file `core/sync/data_source_manager.py` is the orchestrator responsible for retrieving **1-minute Bitcoin data** for SPOT, UM, or CM markets. In this upgrade, we extend the legacy **Failover Composition Priority (FCP)** to an iterative merging strategy dubbed **Failover Composition and Parcel Merge (FCP-PM)**.

## Mechanism Overview

The FCP-PM mechanism now operates as follows:

1. **Local Cache Retrieval**
   - **Purpose:** Leverage local Apache Arrow files to quickly obtain data.
   - **Process:** Data is memory-mapped and assumed valid without expiration. Any data successfully retrieved from cache is immediately merged into the output dataset.
   
2. **Vision API Retrieval with Iterative Merge**
   - **Purpose:** Supplement missing data segments identified after cache retrieval.
   - **Process:** The system compares the desired time span against the merged cache data. If gaps are found, it performs targeted queries to the Vision API.
   - **Merge:** Data retrieved from the Vision API is merged *iteratively* with the already available cache dataâ€”using `open_time` as the alignment index and enforcing 1-minute granularity.
   
3. **REST API Fallback with Final Merge**
   - **Purpose:** Ensure complete data coverage by requesting any remaining segments missing after merging cache and Vision data.
   - **Process:** The REST API is queried for the precise missing ranges.
   - **Merge:** Retrieved REST data is merged with the cumulative data from cache and Vision, standardizing the schema via `_standardize_columns` to match the REST API standard.
   
## Key Features of the FCP-PM Upgrade

- **Iterative Merge Operations:**
  - Data is merged immediately after retrieval at each stage to form a progressively more complete dataset.
  - This prevents redundant network calls by limiting later queries to only the missing data segments.
  
- **Full Parcel Merge Orchestration:**
  - The process continuously checks and reconciles for missing segments as it transitions between data sources.
  - Each merging stage is aware of the current state of the dataset, ensuring no over-fetching or reordering of valid data.
  
- **Dataframe Consistency:**
  - At every merge point, the `_standardize_columns` method ensures consistency in column names and order.
  - The final output DataFrame has a uniform schema aligned to the REST API standard.
  - Data sources (Cache, Vision, or REST) are explicitly identified in the resulting metadata for auditability.
  
- **Robust Retry and Failure Handling:**
  - All network calls utilize `tenacity` with exponential backoff for up to **3 retries** (totaling a max of **30 seconds**).
  - On cumulative failure across all sources, the system exits with a critical error, thereby eliminating the risk of returning an empty DataFrame.

## Additional Configuration and Testing Guidelines

- **Configuration and Constraints:**
  - `utils/market_constraints.py` remains the single source of truth for market data types and constraints.
  - `utils/config.py` holds all runtime parameter definitions.
  - `utils/gap_detector.py` is solely responsible for identifying data gaps.
  - Any discovered code-enforced request limits should be removed immediately.

- **Merge Testing Guidelines:**
  - The merge test must cover a time span that includes three distinct segments: data present in cache, data fetchable via Vision API, and data available from the REST API.
  - The test harness should:
    - Confirm that available segments are correctly identified from all sources.
    - Validate that the iterative merging correctly aligns segments based on `open_time` with strict 1-minute granularity.
    - Ensure that data-source identifiers correctly reflect the origin of each merged data segment.

- **Legacy Code Considerations:**
  - Legacy modules within `core/sync/` and `utils/` should be refactored as needed to align with the new FCP-PM mechanism.
  - Any conflicts between the previous async-oriented implementation and the current synchronous, merge-based strategy should be resolved to streamline the process.

Bitcoin (BTC) remains the default focus for testing while the mechanism is designed to be symbol-agnostic.
