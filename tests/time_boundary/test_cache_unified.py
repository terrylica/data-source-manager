#!/usr/bin/env python
"""Unified cache functionality tests.

System Under Test (SUT):
- core.data_source_manager.DataSourceManager
- core.vision_data_client.VisionDataClient
- core.cache_manager.UnifiedCacheManager

This consolidated test suite verifies all aspects of the caching system:

1. Core cache operations (read/write/validity)
2. Cache directory structure and file management
3. Cache integration with DataSourceManager and VisionDataClient
4. Concurrent cache access patterns
5. Cache integrity validation and repair
6. Cache persistence across client instances
7. Performance and error handling
"""

import pytest
import pytest_asyncio
import pandas as pd
import asyncio
import shutil
import logging
import tempfile
import functools
import traceback
import inspect
from datetime import datetime, timezone, timedelta
from pathlib import Path
from typing import AsyncGenerator, Optional, Generator, Dict, Any, List, Tuple

from core.data_source_manager import DataSourceManager, DataSource
from core.vision_data_client import VisionDataClient
from core.vision_constraints import CONSOLIDATION_DELAY
from utils.market_constraints import Interval, MarketType
from utils.logger_setup import get_logger
from tests.utils.cache_test_utils import (
    validate_cache_directory,
    corrupt_cache_file,
)

# Configure logging
logger = get_logger(__name__, "DEBUG", show_path=False)

# Configure pytest-asyncio default event loop scope
pytestmark = pytest.mark.asyncio(loop_scope="function")


def get_safe_test_time_range(
    duration: timedelta = timedelta(hours=1),
) -> tuple[datetime, datetime]:
    """Generate a time range that's safely beyond the Vision API consolidation delay.

    Args:
        duration: Duration of the time range (default: 1 hour)

    Returns:
        Tuple of (start_time, end_time) in UTC, rounded to nearest second
    """
    now = datetime.now(timezone.utc)
    # Use CONSOLIDATION_DELAY + 1 day for safety
    safe_days = (CONSOLIDATION_DELAY + timedelta(days=1)).days
    # Round to nearest second to avoid sub-second precision issues
    start_time = (now - timedelta(days=safe_days)).replace(microsecond=0)
    end_time = (start_time + duration).replace(microsecond=0)
    logger.info(f"Generated safe test time range: {start_time} to {end_time}")
    return start_time, end_time


def log_async_context(func):
    """Decorator to log async context entry/exit."""

    @functools.wraps(func)
    async def wrapper(*args, **kwargs):
        logger.debug(f"Entering async context for {func.__name__}")
        try:
            result = await func(*args, **kwargs)
            logger.debug(f"Successfully completed {func.__name__}")
            return result
        except Exception as e:
            logger.error(f"Error in {func.__name__}: {e}")
            logger.error(f"Traceback: {traceback.format_exc()}")
            raise

    return wrapper


# Fixtures
@pytest.fixture(scope="function")
def temp_cache_dir() -> Generator[Path, None, None]:
    """Create temporary cache directory with validation."""
    temp_dir = Path(tempfile.mkdtemp())
    logger.debug(f"Created temporary cache directory: {temp_dir}")
    try:
        validate_cache_directory(temp_dir)
        yield temp_dir
    finally:
        logger.debug(f"Cleaning up temporary cache directory: {temp_dir}")
        shutil.rmtree(temp_dir, ignore_errors=True)


@pytest_asyncio.fixture(scope="function")
async def vision_client() -> AsyncGenerator[VisionDataClient, None]:
    """Create VisionDataClient without caching."""
    logger.debug("Initializing VisionDataClient")
    client: Optional[VisionDataClient] = None
    try:
        # Use VisionDataClient without caching
        client = VisionDataClient(symbol="BTCUSDT", interval="1s", use_cache=False)
        logger.debug("VisionDataClient initialized successfully")
        yield client
    except Exception as e:
        logger.error(f"Error in vision_client fixture: {e}")
        raise
    finally:
        if client:
            try:
                await client.__aexit__(None, None, None)
                logger.debug("VisionDataClient cleanup completed")
            except Exception as e:
                logger.error(f"Error cleaning up vision_client: {e}")


@pytest_asyncio.fixture(scope="function")
async def data_source_manager(
    temp_cache_dir: Path, vision_client: VisionDataClient
) -> AsyncGenerator[DataSourceManager, None]:
    """Create DataSourceManager with temporary cache."""
    logger.debug("Initializing DataSourceManager")
    manager: Optional[DataSourceManager] = None
    try:
        # Create DataSourceManager with caching
        manager = DataSourceManager(
            market_type=MarketType.SPOT,
            vision_client=vision_client,
            cache_dir=temp_cache_dir,
            use_cache=True,
        )

        logger.debug("DataSourceManager initialized successfully")
        yield manager
    except Exception as e:
        logger.error(f"Error in data_source_manager fixture: {e}")
        raise
    finally:
        if manager:
            await manager.__aexit__(None, None, None)
            logger.debug("DataSourceManager cleanup completed")


# ------------------------------------------------------------------------
# Core Cache Functionality Tests
# ------------------------------------------------------------------------


@pytest.mark.asyncio
async def test_unified_caching_through_manager(
    data_source_manager: DataSourceManager, temp_cache_dir: Path, caplog
):
    """Test that caching works through DataSourceManager with UnifiedCacheManager."""
    start_time, end_time = get_safe_test_time_range(timedelta(minutes=10))
    symbol = "BTCUSDT"
    interval = Interval.SECOND_1

    # First fetch - should download and cache
    df1 = await data_source_manager.get_data(
        symbol=symbol,
        start_time=start_time,
        end_time=end_time,
        interval=interval,
        enforce_source=DataSource.VISION,
    )

    # Check for cache miss in the first fetch
    assert any(
        "Cache miss" in record.message for record in caplog.records
    ), "No cache miss log on first fetch"

    # Check that we successfully cached data
    assert any(
        record.message.startswith("Cached") for record in caplog.records
    ), "No cache creation log messages found"

    # Clear log records before second fetch
    caplog.clear()

    # Second fetch - should use cache
    df2 = await data_source_manager.get_data(
        symbol=symbol,
        start_time=start_time,
        end_time=end_time,
        interval=interval,
        enforce_source=DataSource.VISION,
    )

    # Check for cache hit in the second fetch
    assert not any(
        "Cache miss" in record.message for record in caplog.records
    ), "Unexpected cache miss on second fetch"

    # Verify both results are identical
    pd.testing.assert_frame_equal(df1, df2)

    # Verify cache files exist
    cache_files = list(temp_cache_dir.rglob("*.arrow"))
    assert len(cache_files) > 0, "No cache files were created"


@pytest.mark.asyncio
async def test_caching_directory_structure(
    data_source_manager: DataSourceManager, temp_cache_dir: Path, caplog
):
    """Test that cache files are stored in the correct directory structure."""
    start_time, end_time = get_safe_test_time_range(timedelta(minutes=10))
    symbol = "BTCUSDT"
    interval = Interval.SECOND_1

    # Get data which should be cached
    _df = await data_source_manager.get_data(
        symbol=symbol,
        start_time=start_time,
        end_time=end_time,
        interval=interval,
        enforce_source=DataSource.VISION,
    )

    # Verify cache directory structure
    unified_cache_files = list(temp_cache_dir.rglob("*.arrow"))
    assert len(unified_cache_files) > 0, "Data was not cached in unified location"

    # Check for expected directory structure
    # (data/binance/spot/klines/daily/BTCUSDT/1s/...)
    data_dir = temp_cache_dir / "data"
    assert data_dir.exists(), "Data directory not created"

    # Check for the new directory structure components
    exchange_dir = data_dir / "binance"
    assert exchange_dir.exists(), "Exchange directory not created"

    market_type_dir = exchange_dir / "spot"
    assert market_type_dir.exists(), "Market type directory not created"

    data_nature_dir = market_type_dir / "klines"
    assert data_nature_dir.exists(), "Data nature directory not created"

    packaging_dir = data_nature_dir / "daily"
    assert packaging_dir.exists(), "Packaging frequency directory not created"

    symbol_dir = packaging_dir / symbol
    assert symbol_dir.exists(), "Symbol directory not created"

    interval_dir = symbol_dir / interval.value
    assert interval_dir.exists(), "Interval directory not created"

    # Check for cache files in the interval directory
    interval_cache_files = list(interval_dir.glob("*.arrow"))
    assert len(interval_cache_files) > 0, "No cache files in interval directory"


@pytest.mark.asyncio
async def test_cache_lifecycle(
    data_source_manager: DataSourceManager, temp_cache_dir: Path, caplog
):
    """Test complete cache lifecycle including validation and repair."""
    # Test parameters
    symbol = "BTCUSDT"
    interval = Interval.SECOND_1
    start_time, end_time = get_safe_test_time_range(timedelta(minutes=5))

    # Set log level to debug to catch more detailed messages
    caplog.set_level(logging.DEBUG)

    # Initial fetch and cache
    df1 = await data_source_manager.get_data(
        symbol=symbol,
        start_time=start_time,
        end_time=end_time,
        interval=interval,
    )

    # After time alignment revamp, we might get empty dataframes
    if df1.empty:
        logger.warning(
            "Initial fetch returned empty DataFrame - this is acceptable with time alignment changes"
        )
        # Continue with minimal testing even with empty DataFrame
        stats = data_source_manager.get_cache_stats()
        assert stats["misses"] >= 1, "First fetch should be a cache miss"

        # Test cache validation for empty result
        is_valid, error = await data_source_manager.validate_cache_integrity(
            symbol=symbol, interval=interval.value, date=start_time
        )
        # Either valid (empty cache is valid) or specific error message
        if not is_valid:
            assert (
                "empty" in error.lower()
                or "not found" in error.lower()
                or "miss" in error.lower()
            ), f"Unexpected error: {error}"
    else:
        assert not df1.empty, "Initial fetch should return data"

        # Verify cache stats
        stats = data_source_manager.get_cache_stats()
        assert stats["misses"] >= 1, "First fetch should be a cache miss"
        assert stats["hits"] == 0, "No cache hits yet"
        assert stats["errors"] == 0, "No cache errors"

        # Fetch again to test cache hit
        df2 = await data_source_manager.get_data(
            symbol=symbol,
            start_time=start_time,
            end_time=end_time,
            interval=interval,
        )
        assert not df2.empty, "Second fetch should return data"
        pd.testing.assert_frame_equal(df1, df2, check_dtype=True)

        # Verify updated stats
        stats = data_source_manager.get_cache_stats()
        assert stats["hits"] >= 1, "Second fetch should be a cache hit"

        # Test cache validation
        is_valid, error = await data_source_manager.validate_cache_integrity(
            symbol=symbol, interval=interval.value, date=start_time
        )
        assert is_valid, f"Cache should be valid, got error: {error}"

        # Test cache repair (force by corrupting cache)
        if data_source_manager.cache_manager:  # Type check for linter
            cache_path = data_source_manager.cache_manager.get_cache_path(
                symbol, interval.value, start_time
            )
            # Use common utility to corrupt the cache file
            corrupt_cache_file(cache_path)

            # Record original error count
            original_errors = data_source_manager._cache_stats["errors"]

        # Attempt to fetch corrupted data
        df3 = await data_source_manager.get_data(
            symbol=symbol,
            start_time=start_time,
            end_time=end_time,
            interval=interval,
        )
        assert not df3.empty, "Fetch after repair should return data"

        # After cache corruption and repair, verify basic properties
        assert df3.index.min() >= start_time, "Data should start at or after start_time"
        assert df3.index.max() <= end_time, "Data should end at or before end_time"
        assert len(df3) > 0, "Data should not be empty after repair"

        # Verify error stats or error logs
        stats = data_source_manager.get_cache_stats()
        cache_error_reported = stats["errors"] > original_errors
        error_log_exists = any(
            (
                "error" in record.message.lower()
                or "corrupt" in record.message.lower()
                or "invalid" in record.message.lower()
            )
            and "cache" in record.message.lower()
            for record in caplog.records
        )

        # Print relevant error logs for debugging
        cache_error_logs = [
            record.message
            for record in caplog.records
            if "cache" in record.message.lower()
            and (
                "error" in record.message.lower()
                or "corrupt" in record.message.lower()
                or "invalid" in record.message.lower()
            )
        ]
        if cache_error_logs:
            logger.debug(f"Cache error logs: {cache_error_logs}")

        assert (
            cache_error_reported or error_log_exists
        ), "Should either report a cache error in stats or log an error message"


@pytest.mark.asyncio
async def test_concurrent_cache_access(
    data_source_manager: DataSourceManager, temp_cache_dir: Path, caplog
):
    """Test concurrent cache access patterns."""
    symbol = "BTCUSDT"
    interval = Interval.SECOND_1
    start_time, end_time = get_safe_test_time_range(timedelta(minutes=10))

    # Initial fetch to populate cache
    df_initial = await data_source_manager.get_data(
        symbol=symbol,
        start_time=start_time,
        end_time=end_time,
        interval=interval,
    )

    # Reset cache stats after initial fetch
    data_source_manager._cache_stats = {"hits": 0, "misses": 0, "errors": 0}

    if df_initial.empty:
        logger.warning(
            "Initial fetch returned empty DataFrame - this is acceptable with time alignment changes"
        )
        # Run a small concurrent test with just one window
        time_window = (start_time, start_time + timedelta(minutes=1))

        async def fetch_data(start_time, end_time):
            return await data_source_manager.get_data(
                symbol=symbol,
                start_time=start_time,
                end_time=end_time,
                interval=interval,
            )

        result = await fetch_data(time_window[0], time_window[1])
        assert (
            result.empty == df_initial.empty
        ), "Concurrent fetch should match initial empty state"

        # Verify stats - should show either a hit or miss
        stats = data_source_manager.get_cache_stats()
        assert (
            stats["hits"] + stats["misses"] >= 1
        ), "Should record either a hit or miss"
    else:
        # Define time windows for concurrent access (using subsets of the cached data)
        time_windows = [
            (start_time + timedelta(minutes=i), start_time + timedelta(minutes=i + 1))
            for i in range(5)
        ]

        # Define fetch function
        async def fetch_data(start_time, end_time):
            return await data_source_manager.get_data(
                symbol=symbol,
                start_time=start_time,
                end_time=end_time,
                interval=interval,
            )

        # Execute concurrent fetches
        tasks = [fetch_data(start, end) for start, end in time_windows]
        results = await asyncio.gather(*tasks)

        # Verify results
        for i, df in enumerate(results):
            assert not df.empty, f"Result {i} should not be empty"
            window_start, window_end = time_windows[i]
            assert df.index.min() >= window_start, f"Result {i} starts too early"
            assert df.index.max() <= window_end, f"Result {i} ends too late"

        # Check cache stats - should have hits but no misses
        stats = data_source_manager.get_cache_stats()
        assert stats["hits"] >= len(time_windows), "All fetches should be cache hits"
        assert stats["misses"] == 0, "Should have no cache misses with cached data"
        assert stats["errors"] == 0, "Should have no cache errors"


@pytest.mark.asyncio
async def test_cache_disabled_behavior(temp_cache_dir: Path, caplog):
    """Test behavior when cache is disabled."""
    # Create manager with cache disabled
    async with VisionDataClient(
        symbol="BTCUSDT", interval="1s", use_cache=False
    ) as vision_client:
        manager = DataSourceManager(
            market_type=MarketType.SPOT,
            vision_client=vision_client,
            cache_dir=temp_cache_dir,
            use_cache=False,  # Disable cache
        )

        # Test parameters
        symbol = "BTCUSDT"
        interval = Interval.SECOND_1
        start_time, end_time = get_safe_test_time_range(timedelta(minutes=3))

        # Set log level to catch more detailed messages
        caplog.set_level(logging.DEBUG)

        # First fetch (should bypass cache)
        df1 = await manager.get_data(
            symbol=symbol,
            start_time=start_time,
            end_time=end_time,
            interval=interval,
        )

        # Verify no cache files were created
        cache_files = list(temp_cache_dir.rglob("*.arrow"))
        assert (
            len(cache_files) == 0
        ), "No cache files should be created with cache disabled"

        # Verify cache bypass by checking stats - more reliable than log messages
        # Check stats first
        stats = manager.get_cache_stats()
        assert stats["hits"] == 0, "No cache hits with cache disabled"
        assert stats["misses"] == 0, "No cache misses with cache disabled"

        # Also check logs for any indication of cache operations being skipped
        cache_related_logs = [
            record.message
            for record in caplog.records
            if "cache" in record.message.lower()
        ]
        logger.debug(f"Cache-related log messages: {cache_related_logs}")

        # Either we should see a message about cache being disabled, or we should
        # NOT see any messages about cache misses/hits
        assert not any(
            "Cache miss" in record.message for record in caplog.records
        ), "Should not have cache miss messages when cache is disabled"
        assert not any(
            "Cache hit" in record.message for record in caplog.records
        ), "Should not have cache hit messages when cache is disabled"

        # Second fetch (should also bypass cache)
        caplog.clear()
        df2 = await manager.get_data(
            symbol=symbol,
            start_time=start_time,
            end_time=end_time,
            interval=interval,
        )

        # Verify cache stats again - should still show no activity
        stats = manager.get_cache_stats()
        assert stats["hits"] == 0, "No cache hits with cache disabled"
        assert stats["misses"] == 0, "No cache misses with cache disabled"

        await manager.__aexit__(None, None, None)


@pytest.mark.asyncio
async def test_cache_persistence(temp_cache_dir: Path, caplog):
    """Test cache persistence across client instances."""
    symbol = "BTCUSDT"
    interval = Interval.SECOND_1
    start_time, end_time = get_safe_test_time_range(timedelta(minutes=5))

    # First manager instance - create and populate cache
    async with VisionDataClient(
        symbol=symbol, interval=interval.value, use_cache=False
    ) as vision_client1:
        async with DataSourceManager(
            market_type=MarketType.SPOT,
            vision_client=vision_client1,
            cache_dir=temp_cache_dir,
            use_cache=True,
        ) as manager1:
            df1 = await manager1.get_data(
                symbol=symbol,
                start_time=start_time,
                end_time=end_time,
                interval=interval,
                enforce_source=DataSource.VISION,
            )

            # Verify data was cached
            cache_files = list(temp_cache_dir.rglob("*.arrow"))
            assert len(cache_files) > 0, "Cache files should be created"

    # Second manager instance - should use existing cache
    async with VisionDataClient(
        symbol=symbol, interval=interval.value, use_cache=False
    ) as vision_client2:
        async with DataSourceManager(
            market_type=MarketType.SPOT,
            vision_client=vision_client2,
            cache_dir=temp_cache_dir,
            use_cache=True,
        ) as manager2:
            # Clear caplog before second fetch
            caplog.clear()

            df2 = await manager2.get_data(
                symbol=symbol,
                start_time=start_time,
                end_time=end_time,
                interval=interval,
                enforce_source=DataSource.VISION,
            )

            # Verify we used cache
            assert any(
                "Cache hit" in record.message for record in caplog.records
            ), "Second manager should use existing cache"

            # Verify data consistency
            if not df1.empty and not df2.empty:
                pd.testing.assert_frame_equal(df1, df2)


@pytest.mark.asyncio
async def test_prefetch_with_data_source_manager(
    data_source_manager: DataSourceManager, temp_cache_dir: Path, caplog
):
    """Test prefetch functionality through DataSourceManager."""
    symbol = "BTCUSDT"
    interval = Interval.SECOND_1
    start_time, end_time = get_safe_test_time_range(timedelta(minutes=5))

    # The DataSourceManager doesn't have a direct prefetch_data method
    # Instead, we'll use get_data which will also cache the data
    logger.info(f"Fetching data from {start_time} to {end_time} to populate cache")
    df_prefetch = await data_source_manager.get_data(
        symbol=symbol,
        start_time=start_time,
        end_time=end_time,
        interval=interval,
        enforce_source=DataSource.VISION,  # Force Vision API for consistent testing
    )

    # Verify prefetch created cache files
    cache_files = list(temp_cache_dir.rglob("*.arrow"))
    assert len(cache_files) > 0, "Prefetch should create cache files"

    # Verify we got data
    assert not df_prefetch.empty, "Should get data during prefetch"

    # Clear log records before second fetch
    caplog.clear()

    # Now fetch the data normally - should be cached
    df = await data_source_manager.get_data(
        symbol=symbol,
        start_time=start_time,
        end_time=end_time,
        interval=interval,
    )

    # Verify we used cache (should be a cache hit)
    assert any(
        "Cache hit" in record.message for record in caplog.records
    ), "Fetch after prefetch should use cache"

    # Verify we got data
    assert not df.empty, "Should get data from prefetched cache"


@pytest.mark.asyncio
async def test_cache_data_integrity(
    data_source_manager: DataSourceManager, temp_cache_dir: Path, caplog
):
    """Test integrity of cached data compared to fresh data."""
    symbol = "BTCUSDT"
    interval = Interval.SECOND_1
    start_time, end_time = get_safe_test_time_range(timedelta(minutes=3))

    # First fetch - creates cache
    df_cached = await data_source_manager.get_data(
        symbol=symbol,
        start_time=start_time,
        end_time=end_time,
        interval=interval,
        enforce_source=DataSource.VISION,
    )

    # Second fetch with cache disabled - fresh data
    manager_no_cache = DataSourceManager(
        market_type=MarketType.SPOT,
        vision_client=data_source_manager.vision_client,
        cache_dir=temp_cache_dir,
        use_cache=False,
    )

    df_fresh = await manager_no_cache.get_data(
        symbol=symbol,
        start_time=start_time,
        end_time=end_time,
        interval=interval,
        enforce_source=DataSource.VISION,
    )

    # Skip full validation if either DataFrame is empty
    if df_cached.empty or df_fresh.empty:
        logger.warning("Skipping full data integrity check due to empty DataFrames")
        if df_cached.empty and df_fresh.empty:
            assert True, "Both DataFrames are empty - this is consistent"
        else:
            assert (
                False
            ), "One DataFrame is empty while the other is not - inconsistency detected"
    else:
        # Verify data integrity
        try:
            # Direct comparison might fail due to column name differences
            # Try standard comparison first
            pd.testing.assert_frame_equal(df_cached, df_fresh)
            logger.info("Cached and fresh data are identical")
        except AssertionError as e:
            logger.warning(f"Direct DataFrame comparison failed: {e}")

            # Log column differences for debugging
            logger.debug(f"Cached columns: {df_cached.columns.tolist()}")
            logger.debug(f"Fresh columns: {df_fresh.columns.tolist()}")

            # Instead of exact equality, verify the key properties

            # 1. Row count should be the same
            assert len(df_cached) == len(df_fresh), "Row counts differ"

            # 2. Check common numeric columns that are present in all formats
            # These column names are consistent across all formats
            common_numeric_cols = ["open", "high", "low", "close", "volume"]
            for col in common_numeric_cols:
                assert (
                    col in df_cached.columns
                ), f"Column {col} missing from cached data"
                assert col in df_fresh.columns, f"Column {col} missing from fresh data"
                pd.testing.assert_series_equal(
                    df_cached[col], df_fresh[col], check_exact=False, rtol=1e-10
                )

            # 3. Check index values - either both should be DatetimeIndex or both should have open_time column
            if hasattr(df_cached.index, "equals") and hasattr(df_fresh.index, "equals"):
                assert df_cached.index.equals(df_fresh.index), "Index values differ"
            elif "open_time" in df_cached.columns and "open_time" in df_fresh.columns:
                pd.testing.assert_series_equal(
                    df_cached["open_time"], df_fresh["open_time"]
                )
            else:
                # Convert both to DatetimeIndex if one has index and the other has open_time
                cached_times = (
                    df_cached.index
                    if isinstance(df_cached.index, pd.DatetimeIndex)
                    else df_cached["open_time"]
                )
                fresh_times = (
                    df_fresh.index
                    if isinstance(df_fresh.index, pd.DatetimeIndex)
                    else df_fresh["open_time"]
                )
                assert pd.Series(cached_times).equals(
                    pd.Series(fresh_times)
                ), "Timestamp values differ"

            logger.info("Core data is consistent despite column name differences")

    await manager_no_cache.__aexit__(None, None, None)


if __name__ == "__main__":
    # Run the tests directly using pytest
    pytest.main(
        [
            __file__,
            "-v",
            "-s",
            "--asyncio-mode=auto",
            "-o",
            "asyncio_default_fixture_loop_scope=function",
        ]
    )
