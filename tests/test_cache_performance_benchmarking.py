#!/usr/bin/env python
"""Integration tests for cache performance benchmarking.

Focus areas:
1. Basic cache hit/miss performance
2. Memory usage patterns
3. Data consistency verification
4. Cache vs. no-cache timing comparisons
"""

import pytest
import arrow
import pandas as pd
import time
import psutil
import os
from datetime import timedelta, datetime
from typing import Tuple, Dict, List, Any, AsyncGenerator
import pytest_asyncio

from utils.logger_setup import get_logger
from core.data_source_manager import DataSourceManager
from utils.market_constraints import Interval, MarketType

logger = get_logger(__name__, "INFO", show_path=False, rich_tracebacks=True)

# Test configuration
TEST_SYMBOL = "BTCUSDT"  # Use BTC for reliable data
TEST_INTERVAL = Interval.SECOND_1  # Focus on 1-second data

# Time constants for tests
HOUR = timedelta(hours=1)
DAY = timedelta(days=1)


def get_memory_usage() -> float:
    """Get current memory usage in MB."""
    process = psutil.Process(os.getpid())
    return process.memory_info().rss / 1024 / 1024


def log_performance_metrics(
    operation: str,
    start_time: float,
    end_time: float,
    start_memory: float,
    end_memory: float,
    df: pd.DataFrame,
) -> None:
    """Log detailed performance metrics for an operation."""
    duration = end_time - start_time
    memory_change = end_memory - start_memory

    logger.info(
        "â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•"
    )
    logger.info(f"â•‘ ğŸ“Š PERFORMANCE METRICS - {operation}")
    logger.info(
        "â• â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•"
    )
    logger.info("â•‘ â±ï¸  Timing Metrics:")
    logger.info(f"â•‘   â€¢ Total Duration: {duration:.4f} seconds")
    logger.info(f"â•‘   â€¢ Per Record: {(duration * 1000 / len(df)):.4f} ms/record")
    logger.info("â•‘")
    logger.info("â•‘ ğŸ’¾ Memory Metrics:")
    logger.info(f"â•‘   â€¢ Initial Memory: {start_memory:.2f} MB")
    logger.info(f"â•‘   â€¢ Final Memory: {end_memory:.2f} MB")
    logger.info(f"â•‘   â€¢ Memory Change: {memory_change:+.2f} MB")
    logger.info("â•‘")
    logger.info("â•‘ ğŸ“ˆ Data Metrics:")
    logger.info(f"â•‘   â€¢ Records Processed: {len(df):,}")
    logger.info(f"â•‘   â€¢ Memory per Record: {(memory_change / len(df)):.4f} MB/record")
    logger.info(
        "â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•"
    )


async def perform_data_fetch(
    manager: DataSourceManager,
    start_time: datetime,
    end_time: datetime,
    use_cache: bool,
) -> Tuple[pd.DataFrame, float, float, float, float]:
    """Perform data fetch and measure performance metrics."""
    start_memory = get_memory_usage()
    start_time_perf = time.perf_counter()

    df = await manager.get_data(
        symbol=TEST_SYMBOL,
        interval=TEST_INTERVAL,
        start_time=start_time,
        end_time=end_time,
        use_cache=use_cache,
    )

    end_time_perf = time.perf_counter()
    end_memory = get_memory_usage()

    return df, start_time_perf, end_time_perf, start_memory, end_memory


@pytest_asyncio.fixture
async def manager() -> AsyncGenerator[DataSourceManager, None]:
    """Create DataSourceManager instance with fresh components."""
    async with DataSourceManager(market_type=MarketType.SPOT) as mgr:
        yield mgr


@pytest.mark.real
@pytest.mark.asyncio
async def test_basic_cache_performance(manager: DataSourceManager) -> None:
    """Test basic cache performance with cold and warm cache scenarios."""
    logger.info("")
    logger.info(
        "â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•"
    )
    logger.info("â•‘ ğŸ§ª TEST CASE: Basic Cache Performance")
    logger.info(
        "â• â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•"
    )
    logger.info("â•‘ ğŸ¯ MOTIVATION:")
    logger.info(
        "â•‘   Measuring and comparing performance characteristics between cache hits and misses"
    )
    logger.info(
        "â•‘   to understand the performance impact of caching in typical usage scenarios."
    )
    logger.info("â•‘")
    logger.info("â•‘ ğŸ“‹ TEST SEQUENCE:")
    logger.info("â•‘   1. Cold cache fetch (cache miss)")
    logger.info("â•‘   2. Warm cache fetch (cache hit)")
    logger.info("â•‘   3. Performance comparison")
    logger.info(
        "â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•"
    )

    # Test parameters
    base_time = arrow.utcnow().shift(days=-2)
    start_time = base_time.datetime
    end_time = base_time.shift(minutes=5).datetime

    # Cold cache fetch (cache miss)
    logger.info("Performing cold cache fetch (cache miss)...")
    df_cold, start_cold, end_cold, start_mem_cold, end_mem_cold = (
        await perform_data_fetch(manager, start_time, end_time, use_cache=True)
    )
    log_performance_metrics(
        "Cold Cache Fetch", start_cold, end_cold, start_mem_cold, end_mem_cold, df_cold
    )

    # Warm cache fetch (cache hit)
    logger.info("\nPerforming warm cache fetch (cache hit)...")
    df_warm, start_warm, end_warm, start_mem_warm, end_mem_warm = (
        await perform_data_fetch(manager, start_time, end_time, use_cache=True)
    )
    log_performance_metrics(
        "Warm Cache Fetch", start_warm, end_warm, start_mem_warm, end_mem_warm, df_warm
    )

    # Compare results
    cold_duration = end_cold - start_cold
    warm_duration = end_warm - start_warm
    speedup = cold_duration / warm_duration if warm_duration > 0 else float("inf")

    logger.info("")
    logger.info(
        "â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•"
    )
    logger.info("â•‘ ğŸ“Š CACHE PERFORMANCE COMPARISON")
    logger.info(
        "â• â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•"
    )
    logger.info(f"â•‘ â€¢ Cold Cache Duration: {cold_duration:.4f} seconds")
    logger.info(f"â•‘ â€¢ Warm Cache Duration: {warm_duration:.4f} seconds")
    logger.info(f"â•‘ â€¢ Cache Speedup Factor: {speedup:.2f}x")
    logger.info("â•‘")
    logger.info("â•‘ Memory Impact:")
    logger.info(
        f"â•‘ â€¢ Cold Cache Memory Change: {end_mem_cold - start_mem_cold:+.2f} MB"
    )
    logger.info(
        f"â•‘ â€¢ Warm Cache Memory Change: {end_mem_warm - start_mem_warm:+.2f} MB"
    )
    logger.info(
        "â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•"
    )

    # Verify data consistency
    pd.testing.assert_frame_equal(
        df_cold,
        df_warm,
        check_dtype=True,
        check_index_type=True,
        check_column_type=True,
    )


@pytest.mark.real
@pytest.mark.asyncio
async def test_cache_vs_no_cache_comparison(manager: DataSourceManager) -> None:
    """Compare performance between cached and non-cached data retrieval."""
    logger.info("")
    logger.info(
        "â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•"
    )
    logger.info("â•‘ ğŸ§ª TEST CASE: Cache vs. No-Cache Comparison")
    logger.info(
        "â• â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•"
    )
    logger.info("â•‘ ğŸ¯ MOTIVATION:")
    logger.info(
        "â•‘   Directly comparing performance characteristics between cached and non-cached data retrieval"
    )
    logger.info("â•‘   to quantify the benefits and overhead of caching.")
    logger.info("â•‘")
    logger.info("â•‘ ğŸ“‹ TEST SEQUENCE:")
    logger.info("â•‘   1. No-cache fetch")
    logger.info("â•‘   2. Cached fetch")
    logger.info("â•‘   3. Performance comparison")
    logger.info(
        "â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•"
    )

    # Test parameters
    base_time = arrow.utcnow().shift(days=-2)
    start_time = base_time.datetime
    end_time = base_time.shift(minutes=5).datetime

    # No-cache fetch
    logger.info("Performing no-cache fetch...")
    df_no_cache, start_no_cache, end_no_cache, start_mem_no_cache, end_mem_no_cache = (
        await perform_data_fetch(manager, start_time, end_time, use_cache=False)
    )
    log_performance_metrics(
        "No-Cache Fetch",
        start_no_cache,
        end_no_cache,
        start_mem_no_cache,
        end_mem_no_cache,
        df_no_cache,
    )

    # Cache fetch
    logger.info("\nPerforming cached fetch...")
    df_cache, start_cache, end_cache, start_mem_cache, end_mem_cache = (
        await perform_data_fetch(manager, start_time, end_time, use_cache=True)
    )
    log_performance_metrics(
        "Cached Fetch", start_cache, end_cache, start_mem_cache, end_mem_cache, df_cache
    )

    # Compare results
    no_cache_duration = end_no_cache - start_no_cache
    cache_duration = end_cache - start_cache
    performance_diff = ((no_cache_duration - cache_duration) / no_cache_duration) * 100

    logger.info("")
    logger.info(
        "â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•"
    )
    logger.info("â•‘ ğŸ“Š CACHE VS. NO-CACHE COMPARISON")
    logger.info(
        "â• â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•"
    )
    logger.info(f"â•‘ â€¢ No-Cache Duration: {no_cache_duration:.4f} seconds")
    logger.info(f"â•‘ â€¢ Cache Duration: {cache_duration:.4f} seconds")
    logger.info(f"â•‘ â€¢ Performance Improvement: {performance_diff:+.2f}%")
    logger.info("â•‘")
    logger.info("â•‘ Memory Impact:")
    logger.info(
        f"â•‘ â€¢ No-Cache Memory Change: {end_mem_no_cache - start_mem_no_cache:+.2f} MB"
    )
    logger.info(f"â•‘ â€¢ Cache Memory Change: {end_mem_cache - start_mem_cache:+.2f} MB")
    logger.info(
        "â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•"
    )

    # Verify data consistency
    pd.testing.assert_frame_equal(
        df_no_cache,
        df_cache,
        check_dtype=True,
        check_index_type=True,
        check_column_type=True,
    )


@pytest.mark.real
@pytest.mark.asyncio
async def test_geometric_range_performance(manager: DataSourceManager) -> None:
    """Test cache performance with geometrically increasing data ranges."""
    logger.info("")
    logger.info(
        "â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•"
    )
    logger.info("â•‘ ğŸ§ª TEST CASE: Geometric Range Performance")
    logger.info(
        "â• â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•"
    )
    logger.info("â•‘ ğŸ¯ MOTIVATION:")
    logger.info(
        "â•‘   Analyzing how cache performance scales with geometrically increasing data ranges"
    )
    logger.info(
        "â•‘   to understand the relationship between data size and performance benefits."
    )
    logger.info("â•‘")
    logger.info("â•‘ ğŸ“‹ TEST SEQUENCE:")
    logger.info("â•‘   1. Test with 5-minute range")
    logger.info("â•‘   2. Test with 15-minute range")
    logger.info("â•‘   3. Test with 30-minute range")
    logger.info("â•‘   4. Test with 1-hour range")
    logger.info("â•‘   5. Performance scaling analysis")
    logger.info(
        "â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•"
    )

    # Test ranges in minutes
    ranges = [5, 15, 30, 60]
    base_time = arrow.utcnow().shift(days=-2)
    results: List[Dict[str, Any]] = []

    for minutes in ranges:
        logger.info(f"\nTesting {minutes}-minute range...")
        start_time = base_time.datetime
        end_time = base_time.shift(minutes=minutes).datetime

        # Cold cache fetch
        logger.info(f"Performing cold cache fetch for {minutes}-minute range...")
        df_cold, start_cold, end_cold, start_mem_cold, end_mem_cold = (
            await perform_data_fetch(manager, start_time, end_time, use_cache=True)
        )
        cold_duration = end_cold - start_cold
        cold_memory = end_mem_cold - start_mem_cold
        log_performance_metrics(
            f"Cold Cache Fetch ({minutes}min)",
            start_cold,
            end_cold,
            start_mem_cold,
            end_mem_cold,
            df_cold,
        )

        # Warm cache fetch
        logger.info(f"Performing warm cache fetch for {minutes}-minute range...")
        df_warm, start_warm, end_warm, start_mem_warm, end_mem_warm = (
            await perform_data_fetch(manager, start_time, end_time, use_cache=True)
        )
        warm_duration = end_warm - start_warm
        warm_memory = end_mem_warm - start_mem_warm
        log_performance_metrics(
            f"Warm Cache Fetch ({minutes}min)",
            start_warm,
            end_warm,
            start_mem_warm,
            end_mem_warm,
            df_warm,
        )

        # Store results
        results.append(
            {
                "range_minutes": minutes,
                "records": len(df_cold),
                "cold_duration": cold_duration,
                "warm_duration": warm_duration,
                "cold_memory": cold_memory,
                "warm_memory": warm_memory,
                "speedup": (
                    cold_duration / warm_duration if warm_duration > 0 else float("inf")
                ),
                "memory_efficiency": (
                    cold_memory / warm_memory if warm_memory > 0 else float("inf")
                ),
            }
        )

        # Verify data consistency
        pd.testing.assert_frame_equal(
            df_cold,
            df_warm,
            check_dtype=True,
            check_index_type=True,
            check_column_type=True,
        )

    # Log scaling analysis
    logger.info("")
    logger.info(
        "â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•"
    )
    logger.info("â•‘ ğŸ“Š PERFORMANCE SCALING ANALYSIS")
    logger.info(
        "â• â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•"
    )
    logger.info(
        "â•‘ Range  Records  Cold(s)  Warm(s)  Speedup  Cold Mem(MB)  Warm Mem(MB)  Mem.Eff"
    )
    logger.info(
        "â•‘ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€"
    )

    for result in results:
        range_min: int = result["range_minutes"]
        record_count: int = result["records"]
        cold_dur: float = result["cold_duration"]
        warm_dur: float = result["warm_duration"]
        speedup_val: float = result["speedup"]
        cold_mem: float = result["cold_memory"]
        warm_mem: float = result["warm_memory"]
        mem_eff: float = result["memory_efficiency"]

        logger.info(
            f"â•‘ {range_min:3}m  {record_count:7}  {cold_dur:7.3f}  "
            f"{warm_dur:7.3f}  {speedup_val:7.2f}x  {cold_mem:11.2f}  "
            f"{warm_mem:11.2f}  {mem_eff:7.2f}x"
        )

    logger.info(
        "â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•"
    )

    # Calculate and log performance trends
    record_sizes: List[int] = [r["records"] for r in results]
    speedups: List[float] = [r["speedup"] for r in results]
    mem_effs: List[float] = [r["memory_efficiency"] for r in results]

    logger.info("")
    logger.info(
        "â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•"
    )
    logger.info("â•‘ ğŸ“ˆ PERFORMANCE TRENDS")
    logger.info(
        "â• â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•"
    )
    logger.info(f"â•‘ â€¢ Records Growth: {', '.join(f'{s:,}' for s in record_sizes)}")
    logger.info(f"â•‘ â€¢ Speedup Trend: {', '.join(f'{s:.2f}x' for s in speedups)}")
    logger.info(
        f"â•‘ â€¢ Memory Efficiency Trend: {', '.join(f'{m:.2f}x' for m in mem_effs)}"
    )
    logger.info(
        "â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•"
    )
