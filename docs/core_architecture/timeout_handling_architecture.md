# Centralized Timeout Handling Architecture

## Overview

The centralized timeout handling system in Data Source Manager provides a consistent, reliable approach to managing network operations with proper time constraints. This architecture ensures that all data retrieval operations have uniform timeout behavior, detailed logging of timeout incidents, and clean resource management when timeouts occur.

```diagram
┌─────────────────┐      ┌─────────────────────┐      ┌─────────────────────────┐
│                 │      │                     │      │                         │
│ MAX_TIMEOUT     │─────▶│ Data Client         │─────▶│ Timeout Logger         │
│ in config.py    │      │ (Vision/REST)       │      │ in logger_setup.py     │
│                 │      │                     │      │                         │
└─────────────────┘      └─────────────────────┘      └─────────────────────────┘
                                   │                              │
                                   ▼                              ▼
                        ┌─────────────────────┐      ┌─────────────────────────┐
                        │                     │      │                         │
                        │ Task Cancellation   │      │ Timeout Log File        │
                        │ & Resource Cleanup  │      │ in logs/timeout_incidents│
                        │                     │      │                         │
                        └─────────────────────┘      └─────────────────────────┘
```

## Key Components

### 1. Centralized Timeout Configuration

The system uses a centralized timeout constant defined in `src/data_source_manager/utils/config.py`:

```python
MAX_TIMEOUT: Final = 9.0  # Maximum timeout for any individual operation
```

Key features:

- Provides a consistent maximum timeout value across all components
- Acts as a system-wide cap for any timeout settings
- Creates a single point of configuration for timeout values

### 2. Specialized Timeout Logging

The `src/data_source_manager/utils/logger_setup.py` module implements specialized logging for timeout events:

```python
def log_timeout(self, operation: str, timeout_value: float, details: dict = None):
    """Log a timeout event to both console and dedicated timeout log file."""
    # ...
```

Key features:

- Records timeout events in both console output and a dedicated log file
- Captures operation name, timeout value, and detailed context
- Maintains a central registry of all timeout incidents

### 3. Dedicated Timeout Log Storage

Timeout logs are stored in a dedicated directory structure:

```tree
/logs
  /timeout_incidents
    timeout_log.txt
    test_rest_cleanup.log
    test_timeout.log
    ...
```

Key features:

- Organizes timeout logs for easy analysis
- Persists timeout history for troubleshooting and pattern detection
- Separates timeout logs from general application logs

## Implementation in Data Clients

### VisionDataClient Timeout Implementation

The `VisionDataClient.fetch` method implements timeout handling as follows:

```python
async def fetch(self, symbol, interval, start_time, end_time):
    # Create a task for the download operation
    download_task = asyncio.create_task(self._download_data(...))

    try:
        # Wait for the task with timeout
        result = await asyncio.wait_for(download_task, timeout=MAX_TIMEOUT)
        # Process and return result

    except asyncio.TimeoutError:
        # Log timeout with detailed context
        logger.log_timeout(
            operation=f"Vision API download for {symbol}",
            timeout_value=MAX_TIMEOUT,
            details={...}
        )

        # Cancel the download task
        if not download_task.done():
            download_task.cancel()

        # Clean up resources
        # Return appropriate fallback response
```

### RestDataClient Timeout Implementation

The `RestDataClient.fetch` method implements a similar pattern with additional task tracking:

```python
async def fetch(self, symbol, interval, start_time, end_time):
    # Set up timeout for the overall fetch operation
    effective_timeout = min(MAX_TIMEOUT, self.fetch_timeout * 2)

    # Create a task for the chunked fetch operation
    all_chunks_task = asyncio.create_task(self._fetch_all_chunks(...))

    try:
        # Wait for the task with timeout
        results = await asyncio.wait_for(all_chunks_task, timeout=effective_timeout)
        # Process and return results

    except asyncio.TimeoutError:
        # Log timeout with detailed context
        logger.log_timeout(
            operation=f"REST API fetch for {symbol} {interval.value}",
            timeout_value=effective_timeout,
            details={...}
        )

        # Cancel the task and clean up resources
        if not all_chunks_task.done():
            all_chunks_task.cancel()

        await self._cleanup_force_timeout_tasks()
        # Return appropriate fallback response
```

The `RestDataClient` also includes a dedicated cleanup method to handle hanging tasks:

```python
async def _cleanup_force_timeout_tasks(self):
    """Force cleanup of any hanging tasks during timeout.

    This is a special method called when timeout occurs to ensure
    we don't leave any hanging tasks or connections in the background.
    """
    # Cancel active tasks
    # Close client session
    # Clean up resources
```

## Benefits of the Architecture

1. **Consistency**: All data clients follow the same timeout handling pattern
2. **Visibility**: Timeout incidents are centrally logged for monitoring and analysis
3. **Resource Management**: Proper cancellation and cleanup prevents resource leaks
4. **Fallback Handling**: Each client provides appropriate fallback behavior
5. **Configurability**: Single point of configuration for timeout values

## Testing and Verification

The timeout handling architecture is verified through dedicated tests:

```python
@pytest.mark.asyncio
async def test_timeout_handling():
    """Test that timeout is properly handled and logged."""
    # Setup temporary log file
    # Configure client with short timeout
    # Attempt operation that will timeout
    # Verify timeout was logged correctly
```

These tests ensure that:

- Timeouts are properly detected
- Tasks are properly cancelled
- Resources are cleaned up
- Timeout events are correctly logged
- Fallback behavior works as expected

## Conclusion

The centralized timeout handling architecture provides a robust foundation for managing network operations with proper time constraints. By standardizing timeout behavior, logging, and resource management across all data clients, the system ensures reliable operation even in challenging network conditions.
