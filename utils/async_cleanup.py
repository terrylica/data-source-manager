#!/usr/bin/env python

"""Utilities for safe cleanup of async resources in Python 3.13+.

This module provides utilities for handling resource cleanup in a way that's compatible
with Python 3.13's stricter handling of coroutines and avoids "coroutine never awaited"
warnings, hanging during cleanup, and resource leaks.

Key features:
- Timeout protection for all cleanup operations
- Error handling that prevents exceptions from propagating
- Specialized handling for HTTP clients like curl_cffi.AsyncSession
- Support for both async and sync cleanup methods
- Garbage collection forcing to help with circular references

Usage examples:

1. Basic usage in a class:

```python
from utils.async_cleanup import direct_resource_cleanup

class MyAsyncResource:
    async def __aenter__(self):
        self._client = create_client()
        self._other_resource = await create_other_resource()
        return self

    async def __aexit__(self, exc_type, exc_val, exc_tb):
        await direct_resource_cleanup(
            self,
            ("_client", "HTTP client", False),
            ("_other_resource", "other resource", False),
        )
```

2. For more complex cleanup needs:

```python
from utils.async_cleanup import close_resource_with_timeout, cleanup_client

async def __aexit__(self, exc_type, exc_val, exc_tb):
    # Handle special resources first
    if hasattr(self, "_special_resource") and self._special_resource:
        # Custom cleanup logic
        self._special_resource.special_sync_cleanup()
        self._special_resource = None

    # Then use the utilities for standard resources
    await cleanup_client(self._client, is_external=self._client_is_external)
    await close_resource_with_timeout(
        self._other_resource,
        timeout=0.2,  # Custom timeout
        resource_name="important resource"
    )

    # Force garbage collection
    gc.collect()
```

3. With custom close method:

```python
await close_resource_with_timeout(
    resource=self._websocket,
    close_method="disconnect",  # Method name other than __aexit__
    close_args=(),
    timeout=0.5
)
```
"""

import asyncio
import gc
from typing import Any, Callable, Optional, TypeVar, Union
import inspect
import sys

from utils.logger_setup import logger
from utils.config import (
    RESOURCE_CLEANUP_TIMEOUT,
    HTTP_CLIENT_CLEANUP_TIMEOUT,
    FILE_CLEANUP_TIMEOUT,
    ENABLE_FORCED_GC,
)

logger.setLevel("DEBUG")

T = TypeVar("T")


async def close_resource_with_timeout(
    resource: Any,
    timeout: float = RESOURCE_CLEANUP_TIMEOUT,
    resource_name: str = "resource",
    close_method: str = "__aexit__",
    close_args: tuple = (None, None, None),
) -> None:
    """Close an async resource with timeout protection to prevent hanging.

    Args:
        resource: The async resource to close
        timeout: Maximum time in seconds to wait for resource cleanup (default: from config)
        resource_name: Name of the resource for logging (default: "resource")
        close_method: Name of the close method to call (default: "__aexit__")
        close_args: Arguments to pass to the close method (default: (None, None, None))
    """
    if resource is None:
        logger.debug(f"Skipping cleanup for {resource_name}: resource is None")
        return

    logger.debug(
        f"Starting cleanup for {resource_name} (type: {type(resource).__name__}) with timeout {timeout}s"
    )

    try:
        # Check if the method exists and if it's a coroutine function
        method = getattr(resource, close_method, None)
        if method is None:
            logger.debug(f"{resource_name} does not have a {close_method} method")
            return

        if inspect.iscoroutinefunction(method):
            # For async close methods
            logger.debug(
                f"Using async cleanup for {resource_name} with {close_method}()"
            )
            try:
                await asyncio.shield(
                    asyncio.wait_for(method(*close_args), timeout=timeout)
                )
                logger.debug(f"Successfully closed {resource_name}")
            except asyncio.TimeoutError:
                logger.warning(f"{resource_name} cleanup timed out after {timeout}s")
            except asyncio.CancelledError:
                logger.warning(f"{resource_name} cleanup was cancelled")
        else:
            # For synchronous close methods
            logger.debug(
                f"Using sync cleanup for {resource_name} with {close_method}()"
            )
            method(*close_args)
            logger.debug(f"Successfully closed {resource_name} (sync)")

    except (asyncio.TimeoutError, asyncio.CancelledError) as e:
        logger.debug(f"{resource_name} cleanup timed out or was cancelled: {str(e)}")
    except Exception as e:
        logger.warning(f"Error closing {resource_name}: {str(e)}")
    finally:
        logger.debug(f"Completed cleanup attempt for {resource_name}")


async def cleanup_client(
    client: Any, is_external: bool = False, timeout: float = HTTP_CLIENT_CLEANUP_TIMEOUT
) -> None:
    """Cleanup an HTTP client with timeout protection.

    Handles both curl_cffi AsyncSession and other HTTP clients.

    Args:
        client: The HTTP client to close
        is_external: If True, client won't be closed (it's managed externally)
        timeout: Maximum time in seconds to wait for client cleanup (default: from config)
    """
    if client is None:
        logger.debug("Skipping client cleanup: client is None")
        return

    if is_external:
        logger.debug("Skipping client cleanup: client is external")
        return

    client_type = type(client).__name__
    logger.debug(
        f"Starting cleanup for HTTP client (type: {client_type}) with timeout {timeout}s"
    )

    try:
        # Check for curl_cffi AsyncSession and handle special cases
        if client_type == "AsyncSession" and hasattr(client, "_asynccurl"):
            logger.debug("Detected curl_cffi AsyncSession, using targeted cleanup")

            # First try to clean up the asynccurl object directly
            if hasattr(client._asynccurl, "close") and callable(
                client._asynccurl.close
            ):
                try:
                    client._asynccurl.close()
                    logger.debug("Closed curl_cffi client via _asynccurl.close()")
                except Exception as e:
                    logger.warning(f"Error closing _asynccurl: {e}")

            # Clear the Session's attributes to break circular references
            for attr in ["_asynccurl", "_curlm", "_timeout_handle"]:
                if hasattr(client, attr):
                    try:
                        setattr(client, attr, None)
                        logger.debug(f"Cleared client.{attr} attribute")
                    except:
                        pass

            # Session doesn't have aclose but has close
            if hasattr(client, "close") and callable(client.close):
                if inspect.iscoroutinefunction(client.close):
                    try:
                        await asyncio.shield(
                            asyncio.wait_for(client.close(), timeout=timeout)
                        )
                        logger.debug("Closed curl_cffi client with async close()")
                    except Exception as e:
                        logger.warning(f"Error during client.close(): {e}")
                else:
                    try:
                        client.close()
                        logger.debug("Closed curl_cffi client with sync close()")
                    except Exception as e:
                        logger.warning(f"Error during client.close(): {e}")

            return

        # Try direct aclose if available
        if hasattr(client, "aclose") and callable(client.aclose):
            logger.debug(f"Found aclose() method on client (type: {client_type})")
            try:
                await asyncio.shield(asyncio.wait_for(client.aclose(), timeout=timeout))
                logger.debug("Directly closed HTTP client with aclose()")
                return
            except asyncio.TimeoutError:
                logger.warning(f"HTTP client aclose() timed out after {timeout}s")
            except asyncio.CancelledError:
                logger.warning("HTTP client aclose() was cancelled")
            except Exception as e:
                logger.warning(f"Error during client.aclose(): {e}")

        # Try regular close method
        if hasattr(client, "close") and callable(client.close):
            logger.debug(f"Found close() method on client (type: {client_type})")
            if inspect.iscoroutinefunction(client.close):
                try:
                    await asyncio.shield(
                        asyncio.wait_for(client.close(), timeout=timeout)
                    )
                    logger.debug("Closed HTTP client with async close()")
                    return
                except Exception as e:
                    logger.warning(f"Error during async client.close(): {e}")
            else:
                try:
                    client.close()
                    logger.debug("Closed HTTP client with sync close()")
                    return
                except Exception as e:
                    logger.warning(f"Error during sync client.close(): {e}")

        # Use our utility if available as a last resort
        logger.debug(f"Trying safely_close_client as fallback (type: {client_type})")
        try:
            from utils.network_utils import safely_close_client

            # Check if the client has a _curlm attribute that might be causing issues
            if hasattr(client, "_curlm"):
                logger.debug("Client has _curlm attribute, setting to None first")
                client._curlm = None

            await asyncio.shield(
                asyncio.wait_for(safely_close_client(client), timeout=timeout)
            )
            logger.debug("Safely closed HTTP client with safely_close_client()")
        except ImportError:
            logger.warning(
                "Could not import safely_close_client from utils.network_utils"
            )
        except asyncio.TimeoutError:
            logger.warning(f"safely_close_client() timed out after {timeout}s")
        except asyncio.CancelledError:
            logger.warning("safely_close_client() was cancelled")
        except Exception as e:
            logger.warning(f"Could not safely close client: {str(e)}")

    except (asyncio.TimeoutError, asyncio.CancelledError) as e:
        logger.debug(f"HTTP client cleanup timed out or was cancelled: {str(e)}")
    except Exception as e:
        logger.warning(f"Error closing HTTP client: {str(e)}")
    finally:
        # Last resort measure: clear all attributes to help garbage collection
        if client_type == "AsyncSession":
            for attr_name in dir(client):
                if not attr_name.startswith("__") and hasattr(client, attr_name):
                    try:
                        setattr(client, attr_name, None)
                    except:
                        pass
        logger.debug(f"Completed cleanup attempt for HTTP client (type: {client_type})")


async def cleanup_file_handle(
    file_handle: Any, timeout: float = FILE_CLEANUP_TIMEOUT
) -> None:
    """Cleanup a file handle with timeout protection.

    Handles both sync and async file handles.

    Args:
        file_handle: The file handle to close
        timeout: Maximum time in seconds to wait for async file cleanup (default: from config)
    """
    if file_handle is None:
        return

    try:
        # Try sync close first
        if hasattr(file_handle, "close"):
            file_handle.close()
            logger.debug("Closed file handle (sync)")
            return

        # Try async close if available
        if hasattr(file_handle, "aclose"):
            await asyncio.shield(
                asyncio.wait_for(file_handle.aclose(), timeout=timeout)
            )
            logger.debug("Closed file handle (async)")
            return

        logger.debug("File handle doesn't have close/aclose method")

    except (asyncio.TimeoutError, asyncio.CancelledError) as e:
        logger.debug(f"File handle cleanup timed out or was cancelled: {str(e)}")
    except Exception as e:
        logger.warning(f"Error closing file handle: {str(e)}")


async def direct_resource_cleanup(
    instance: Any,
    *resource_tuples: tuple[str, str, bool],
    force_gc: bool = ENABLE_FORCED_GC,
) -> None:
    """Direct cleanup of resources with timeout protection.

    This is the recommended approach for cleaning up resources in __aexit__ methods,
    providing a simple way to handle cleanup of multiple resources with proper error
    handling and timeout protection.

    Args:
        instance: The object instance containing the resources
        *resource_tuples: Variable number of tuples in the format:
                         (attribute_name, resource_name_for_logs, is_external)
        force_gc: Whether to force garbage collection after cleanup

    Example:
    ```python
    async def __aexit__(self, exc_type, exc_val, exc_tb):
        await direct_resource_cleanup(
            self,
            ("_client", "HTTP client", self._client_is_external),
            ("_download_manager", "download manager", False),
        )
    ```
    """
    if instance is None:
        logger.debug("Skipping resource cleanup: instance is None")
        return

    logger.debug(f"Starting direct resource cleanup for {type(instance).__name__}")

    # First, break any circular references in curl_cffi clients
    for attr_name, resource_name, is_external in resource_tuples:
        # Only handle non-external resources
        if is_external:
            continue

        # Check if the resource exists
        if not hasattr(instance, attr_name) or getattr(instance, attr_name) is None:
            continue

        resource = getattr(instance, attr_name)

        # Special handling for curl_cffi clients - break circular references first
        if "curl" in str(type(resource)).lower() or hasattr(resource, "_curlm"):
            logger.debug(
                f"Found curl_cffi client in {attr_name}, breaking circular references"
            )

            # Nullify _curlm reference that causes circular dependencies
            if hasattr(resource, "_curlm") and resource._curlm is not None:
                logger.debug(f"Nullifying _curlm reference in {resource_name}")
                resource._curlm = None

            # Also clear _timeout_handle if it exists
            if (
                hasattr(resource, "_timeout_handle")
                and resource._timeout_handle is not None
            ):
                logger.debug(f"Nullifying _timeout_handle in {resource_name}")
                resource._timeout_handle = None

    # Cancel any _force_timeout tasks that might be lingering
    await _cancel_force_timeout_tasks()

    # Now proceed with normal resource cleanup
    for attr_name, resource_name, is_external in resource_tuples:
        # Skip if the attribute doesn't exist or is None
        if not hasattr(instance, attr_name) or getattr(instance, attr_name) is None:
            logger.debug(f"Skipping cleanup for {resource_name}: not available")
            continue

        # Get the resource
        resource = getattr(instance, attr_name)

        # Special handling for HTTP clients
        if resource_name.lower() in ("http client", "client", "session"):
            await cleanup_client(resource, is_external)
        # Special handling for file handles
        elif resource_name.lower() in ("file", "file handle"):
            await cleanup_file_handle(resource)
        # General resource cleanup
        else:
            await close_resource_with_timeout(resource, resource_name=resource_name)

        # Set the resource to None to break reference cycles
        if not is_external:
            setattr(instance, attr_name, None)
            logger.debug(f"Set {resource_name} to None after cleanup")

    # Force garbage collection if enabled
    if force_gc:
        collected = gc.collect()
        logger.debug(f"Forced garbage collection: collected {collected} objects")

    logger.debug(f"Completed direct resource cleanup for {type(instance).__name__}")


async def _cancel_force_timeout_tasks() -> int:
    """Find and cancel any _force_timeout tasks that might be active.

    Returns:
        int: Number of tasks cancelled
    """
    cancelled_count = 0
    try:
        # Find all force_timeout tasks
        force_timeout_tasks = []
        for task in asyncio.all_tasks():
            task_str = str(task)
            if "_force_timeout" in task_str and not task.done():
                force_timeout_tasks.append(task)

        # Cancel all found tasks
        if force_timeout_tasks:
            logger.debug(f"Cancelling {len(force_timeout_tasks)} force_timeout tasks")
            for task in force_timeout_tasks:
                task.cancel()
            cancelled_count = len(force_timeout_tasks)

            # Wait for cancellation to complete with timeout
            try:
                await asyncio.wait_for(
                    asyncio.gather(*force_timeout_tasks, return_exceptions=True),
                    timeout=0.5,  # Short timeout to avoid blocking
                )
            except asyncio.TimeoutError:
                logger.warning("Timeout waiting for force_timeout tasks to cancel")

    except Exception as e:
        logger.warning(f"Error cancelling force_timeout tasks: {e}")

    return cancelled_count


async def cleanup_all_force_timeout_tasks():
    """Find and cancel all curl_cffi _force_timeout tasks that might cause hanging.

    This is a global utility function to help resolve hanging issues with curl_cffi
    by directly targeting and cancelling _force_timeout tasks.
    """
    # Find all tasks that might be related to _force_timeout
    force_timeout_tasks = []
    for task in asyncio.all_tasks():
        task_str = str(task)
        # Look specifically for _force_timeout tasks
        if "_force_timeout" in task_str and not task.done():
            force_timeout_tasks.append(task)

    if not force_timeout_tasks:
        logger.debug("No _force_timeout tasks found to clean up")
        return 0

    # Log what we found
    logger.warning(
        f"Found {len(force_timeout_tasks)} hanging _force_timeout tasks to cancel"
    )

    # Cancel futures first, then tasks
    for task in force_timeout_tasks:
        if hasattr(task, "_fut_waiter") and task._fut_waiter is not None:
            try:
                task._fut_waiter.cancel()
            except Exception as e:
                logger.debug(f"Error cancelling future in task: {e}")
        task.cancel()

    # Multi-pass cleanup with escalating measures
    remaining_tasks = force_timeout_tasks
    for attempt in range(3):
        if not remaining_tasks:
            break

        try:
            # Wait for cancellation to complete
            done, pending = await asyncio.wait(
                remaining_tasks,
                timeout=0.5,  # Short timeout
                return_when=asyncio.ALL_COMPLETED,
            )

            remaining_tasks = list(pending)
            logger.debug(
                f"Pass {attempt+1}: {len(done)} tasks done, {len(pending)} tasks pending"
            )

            # If we still have pending tasks after final attempt, try more aggressive approach
            if attempt == 2 and pending:
                logger.warning(
                    f"Attempting aggressive cleanup of {len(pending)} stuck tasks"
                )
                for task in pending:
                    # Try to unblock the task by directly accessing internal APIs
                    if hasattr(task, "_coro"):
                        try:
                            task._coro.throw(asyncio.CancelledError)
                        except Exception:
                            pass
        except Exception as e:
            logger.warning(f"Error during _force_timeout task cleanup: {e}")

    # Force garbage collection to help with circular references
    gc.collect()

    # Special handling for tests
    if "pytest" in sys.modules:
        # Extra sleep and GC in test environments
        try:
            await asyncio.sleep(0.5)
            gc.collect()
        except Exception:
            pass

    return len(force_timeout_tasks) - len(remaining_tasks)
